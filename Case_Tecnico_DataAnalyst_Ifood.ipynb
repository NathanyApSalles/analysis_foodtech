{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqtOgIQ23+cyhwwVhp7fUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathanyApSalles/analysis_foodtech/blob/main/Case_Tecnico_DataAnalyst_Ifood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação das bases"
      ],
      "metadata": {
        "id": "GDeFN_srdPt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "O_7IWENanm7y"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Qtb9n4XVcm29"
      },
      "outputs": [],
      "source": [
        "def read_file(url: str, local_path: str, type_file: str) -> DataFrame:\n",
        "  \"\"\"Função para ler arquivo e retornar um Dataframe.\"\"\"\n",
        "  if not os.path.exists(local_path):\n",
        "    response = requests.get(url)\n",
        "    with open(local_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "  if type_file == \"json\":\n",
        "    return spark.read.json(local_path, multiLine=False)\n",
        "  elif type_file == \"csv\":\n",
        "    return spark.read.option(\"header\", \"true\").csv(local_path)\n",
        "  elif type_file == \"tar\":\n",
        "\n",
        "    arquivos_extraidos = \"/tmp/ab_test_ref\"\n",
        "\n",
        "    os.makedirs(arquivos_extraidos, exist_ok=True)\n",
        "\n",
        "    with tarfile.open(local_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=arquivos_extraidos)\n",
        "\n",
        "    filename = \"\"\n",
        "    for root, dirs, files in os.walk(arquivos_extraidos):\n",
        "        for filename in files:\n",
        "            print(filename) # print para visualizar todos os arquivos exraídos\n",
        "    if \".csv\" in filename: # se houver algum arquivo csv, junte todos os arquivos deste tipo no dataframe\n",
        "      return spark.read.option(\"header\", \"true\").csv(arquivos_extraidos + \"/*.csv\")\n",
        "    else: # se houver algum arquivo json, junte todos os arquivos deste tipo no dataframe\n",
        "      return spark.read.json(arquivos_extraidos + \"/*.json\")\n",
        "      #pode acontecer de ter arquivos de diferentes tipos misturados, mas para este estudo vamos assumir que todos são do mesmo tipo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_pedidos = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/order.json.gz\"\n",
        "url_usuarios = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/consumer.csv.gz\"\n",
        "url_merchants = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/restaurant.csv.gz\"\n",
        "url_test_ab = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/ab_test_ref.tar.gz\"\n",
        "\n",
        "local_path_pedidos = \"/tmp/order.json.gz\"\n",
        "local_path_usuarios = \"/tmp/consumer.csv.gz\"\n",
        "local_path_merchants = \"/tmp/restaurant.csv.gz\"\n",
        "local_path_teste_ab = \"/tmp/ab_test_ref.tar.gz\"\n",
        "\n",
        "pedidos = read_file(url_pedidos, local_path_pedidos, \"json\").cache()\n",
        "usuarios = read_file(url_usuarios, local_path_usuarios, \"csv\").cache()\n",
        "merchants = read_file(url_merchants, local_path_merchants, \"csv\").cache()\n",
        "teste_ab = read_file(url_test_ab, local_path_teste_ab, \"tar\").cache()"
      ],
      "metadata": {
        "id": "S2EDf_Z_ei-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos.show(5)"
      ],
      "metadata": {
        "id": "JLFqLEEMpaYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usuarios.show(5)"
      ],
      "metadata": {
        "id": "JOo2pSgwvxIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merchants.show(5)"
      ],
      "metadata": {
        "id": "dIDvPFqlxGYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste_ab.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "71nIXdCnxILq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, broadcast, when, count, isnan, count_distinct, sum, avg, row_number\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "Or44Op0DmgP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entendendo os dados"
      ],
      "metadata": {
        "id": "H8Quq9ZsldW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_info(df: DataFrame, colunas: list) -> None:\n",
        "  \"\"\"Função para auxiliar a identificar tamanho da base, tipo das colunas,\n",
        "   valores nulos, duplicidade em colunas específicas na base.\"\"\"\n",
        "  # validando o tipo das colunas\n",
        "  df.printSchema()\n",
        "\n",
        "  # validando o tamanho da base\n",
        "  print(f\"Qtd de linhas: {df.count()}\")\n",
        "\n",
        "  print(\"\\nValores nulos\")\n",
        "  df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "  print(\"\\nValidando valores duplicados\")\n",
        "  for column in colunas:\n",
        "    num_duplicados = df.groupBy(column).count().where(col(\"count\") > 1).count()\n",
        "    print(f\"\\n{column}: {num_duplicados}\")"
      ],
      "metadata": {
        "id": "6jlX14IvlcT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info(usuarios, [\"customer_id\"])"
      ],
      "metadata": {
        "id": "qBxwerIon3yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info(pedidos, [\"order_id\"])"
      ],
      "metadata": {
        "id": "4sGDCxaJojFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo os usuários nulos da base\n",
        "# na base de pedidos temos um número pequeno de pedidos sem customer_id atribuído,\n",
        "# porém como o objetivo da análise é validar os resultados do teste a/b, estes pedidos serão removidos visto que\n",
        "# não participaram do teste a/b\n",
        "pedidos_validos_ab = pedidos.where(col(\"customer_id\").isNotNull())"
      ],
      "metadata": {
        "id": "tcZ9ZxgFurDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# podemos ver que a base de pedidos possui uma grande voliumentria de pedidos duplicados\n",
        "# foi analisado uma amostra e notou-se que para os pedidos duplicados, os campos que diferente são CPF e data de criação do pedido\n",
        "# pode ter acontecido algum problema no produto ao gerar o número do pedido, ou até mesmo ao gerar a base,\n",
        "# diantes disto podemos seguir com algumas tratativas, como criar um novo order_id concatenando com o CPF, ou\n",
        "# dentro dos duplicados manter o pedido mais atual, ou a mais antigo.\n",
        "# Como os valores dos pedidos são iguais, merchants, itens também são idênticos, optou-se por manter o pedido mais antigo\n",
        "\n",
        "\n",
        "pedidos_validos_ab = (pedidos_validos_ab\n",
        "                      .withColumn(\"rank\", row_number().over(Window.partitionBy(\"order_id\").orderBy(\"order_created_at\")))\n",
        "                      .where(col(\"rank\") == 1)\n",
        "                      .drop(\"rank\")\n",
        ").cache()\n",
        "df_info(pedidos_validos_ab, [\"order_id\"])"
      ],
      "metadata": {
        "id": "vShWU8hWHote"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info(merchants, [\"id\"])"
      ],
      "metadata": {
        "id": "uYn3IuVWom0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info(teste_ab, [\"customer_id\"])"
      ],
      "metadata": {
        "id": "_ye1-XJEosVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "30hCY7gSqwjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste_ab.groupBy(col(\"is_target\")).agg(count_distinct(\"customer_id\")).show()"
      ],
      "metadata": {
        "id": "4v9X0xxy0gxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_final = pedidos_validos_ab.join(broadcast(teste_ab), ['customer_id'], \"left\").cache()\n",
        "pedidos_final.show(5)"
      ],
      "metadata": {
        "id": "0AX542PvqzXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_final.where(col(\"is_target\").isNull()).show()"
      ],
      "metadata": {
        "id": "atxd_VB75nGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#qtd de pedidos por usuário\n",
        "df_media_pedidos = pedidos_final.groupBy(col(\"customer_id\"), col(\"is_target\")).agg(count_distinct(\"order_id\"), count(\"order_id\"))\n",
        "df_media_pedidos.show(truncate=False)"
      ],
      "metadata": {
        "id": "pBXcTuvM1XqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_final.groupBy(col(\"is_target\")).agg(\n",
        "                                      count_distinct(col(\"order_id\")).alias(\"distinct_orders\"),\n",
        "                                      count_distinct(col(\"customer_id\")).alias(\"distinct_customers\"),\n",
        "                                      count_distinct(col(\"merchant_id\")).alias(\"distinct_merchants\"),\n",
        "                                      sum(col(\"order_total_amount\")).alias(\"order_total_amount\"),\n",
        "                                      avg(col(\"order_total_amount\")).alias(\"order_avg_amount\"),\n",
        "                                      (sum(col(\"order_total_amount\"))/count_distinct(col(\"order_id\"))).alias(\"ticket_medio\"),\n",
        "\n",
        "\n",
        "                                      ).show()"
      ],
      "metadata": {
        "id": "eOjlFF9-q84b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tarquet x control\n",
        "\n",
        "    - qtd de pedidos\n",
        "    - valor total da compra\n",
        "    - ticket médio\n",
        "    - tempo entre compras\n",
        "    - recorrencia\n",
        "    - tem diferença entre usuários ativos ou não?\n",
        "    - expansão geográfica: qtd de estabelecimentos diferentes que compraram\n",
        "    - restaurantes que mais venderam\n",
        "    - região que mais vendeu\n",
        "    - horário das compras\n",
        "    - qtd de produtos adquiridos\n",
        "\n",
        "- ideias para teste ab:\n",
        "\n",
        "    - qtd de usuários que receberam o cupom, para entender conversão, de quem recebeu, quem não comprou;\n",
        "     "
      ],
      "metadata": {
        "id": "rSbOvNnJ1O52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_final.where((col(\"customer_id\") == \"02e1faf7e89415736be3a37c70a2015641a9d652e0fa478b1b2975ce45dfe539\") & (col(\"order_id\") == \"806884e91080e3519aaf60459c08ec179df5ff5aacab3fde085f7073a4254aa8\")).show(30, truncate=False)"
      ],
      "metadata": {
        "id": "vCS0cQSSzqdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicados = pedidos_final.groupBy(\"order_id\").count().filter(\"count > 1\").count()"
      ],
      "metadata": {
        "id": "8I9oszXIBk6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(duplicados)"
      ],
      "metadata": {
        "id": "jVEQ4iwiCXsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}